# åŒ¯å…¥æ‰€éœ€æ¨¡çµ„
import cv2                     # OpenCVï¼Œç”¨æ–¼å½±åƒè™•ç†èˆ‡æ”å½±æ©Ÿæ§åˆ¶
import mediapipe as mp         # MediaPipeï¼Œç”¨æ–¼æ‰‹éƒ¨é—œéµé»åµæ¸¬
import pyautogui               # æ§åˆ¶æ»‘é¼ 
import time                    # è™•ç†æ™‚é–“æ§åˆ¶
from collections import deque  # é›™å‘ä½‡åˆ—ï¼Œç”¨æ–¼å¹³æ»‘åŒ–æ»‘é¼ ç§»å‹•
import numpy as np             # æ•¸å­¸é‹ç®—å·¥å…·
import math                    # æä¾›å¹³æ–¹æ ¹ç­‰åŸºæœ¬æ•¸å­¸å‡½å¼

# åˆ¤æ–·æ˜¯å¦ç‚ºæ¡æ‹³ï¼ˆâœŠï¼‰
def is_fist(landmarks):
    # å®šç¾©å„æŒ‡å°–èˆ‡å°æ‡‰ç¬¬äºŒé—œç¯€çš„ landmark index
    finger_tips = [8, 12, 16, 20]
    finger_pips = [6, 10, 14, 18]
    curled_fingers = 5  # é è¨­èªç‚ºå…¨éƒ¨æ‰‹æŒ‡éƒ½æ˜¯å½æ›²çš„
    threshold = 0.03    # é–¾å€¼ï¼šè¶Šå°ä»£è¡¨è¦æ±‚è¶Šé è¿‘

    # æ¯”è¼ƒæ¯æ ¹æ‰‹æŒ‡å°–èˆ‡ç¬¬äºŒé—œç¯€çš„ y åº§æ¨™
    for tip, pip in zip(finger_tips, finger_pips):
        tip_y = landmarks[tip].y
        pip_y = landmarks[pip].y
        if tip_y > pip_y:  # å¦‚æœæŒ‡å°–æ¯”é—œç¯€é‚„ä½ï¼Œè¡¨ç¤ºå½æ›²
            curled_fingers += 1

    return curled_fingers >= 4  # è‡³å°‘ 4 æ ¹å½æ›²å°±ç•¶ä½œæ¡æ‹³

# å–å¾—è¢å¹•è§£æåº¦
screen_w, screen_h = pyautogui.size()

# åˆå§‹åŒ– MediaPipe Hands æ¨¡çµ„
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils  # ç”¨æ–¼ç•«æ‰‹éƒ¨éª¨æ¶

# å»ºç«‹æ»‘é¼ ç§»å‹•è»Œè·¡çš„ç·©è¡å€ï¼Œç”¨æ–¼å¹³æ»‘åŒ–æ»‘é¼ åº§æ¨™
mouse_history = deque(maxlen=5)

# æ§åˆ¶å®šé»æ“Šé »ç‡ï¼ˆå†·å»æ™‚é–“ï¼‰ï¼Œé¿å…é‡è¤‡è§¸ç™¼
click_cooldown = 0.5
last_click_time = time.time() - click_cooldown

# å•Ÿå‹•æ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

# è¨­å®š OpenCV è¦–çª—ç‚ºå…¨è¢å¹•
cv2.namedWindow("Hand Tracking", cv2.WND_PROP_FULLSCREEN)
cv2.setWindowProperty("Hand Tracking", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

# ä¸»è¿´åœˆ
while cap.isOpened():
    success, frame = cap.read()  # è®€å–æ”å½±æ©Ÿç•«é¢
    if not success:
        continue  # å¦‚æœè®€å–å¤±æ•—å°±è·³éé€™å¹€

    frame = cv2.flip(frame, 1)  # å·¦å³é¡åƒç¿»è½‰ï¼Œç¬¦åˆè‡ªç„¶æ“ä½œ
    h, w, _ = frame.shape       # å–å¾—ç•«é¢é«˜åº¦èˆ‡å¯¬åº¦
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # è½‰æ›é¡è‰²çµ¦ MediaPipe
    result = hands.process(rgb_frame)  # åŸ·è¡Œæ‰‹éƒ¨åµæ¸¬

    # å¦‚æœæœ‰åµæ¸¬åˆ°æ‰‹
    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            # å–å¾— Landmark 4ï¼ˆæ‹‡æŒ‡æŒ‡å°–ï¼‰èˆ‡ Landmark 8ï¼ˆé£ŸæŒ‡æŒ‡å°–ï¼‰
            thumb_tip = hand_landmarks.landmark[4]
            index_tip = hand_landmarks.landmark[8]

            # ç•«å‡ºé£ŸæŒ‡æŒ‡å°–çš„åœ“åœˆæç¤º
            x = int(index_tip.x * w)
            y = int(index_tip.y * h)
            cv2.circle(frame, (x, y), 10, (255, 0, 255), -1)

            # å°‡é£ŸæŒ‡ä½ç½®è½‰æˆè¢å¹•åº§æ¨™
            screen_x = int(index_tip.x * screen_w)
            screen_y = int(index_tip.y * screen_h)
            mouse_history.append((screen_x, screen_y))  # åŠ å…¥æ»‘é¼ æ­·å²ç´€éŒ„

            # ç•¶æ»‘é¼ ç§»å‹•è¨˜éŒ„æ»¿æ™‚ï¼Œè¨ˆç®—å¹³å‡åº§æ¨™ä¸¦ç§»å‹•æ»‘é¼ 
            if len(mouse_history) == mouse_history.maxlen:
                avg_x = int(np.mean([p[0] for p in mouse_history]))
                avg_y = int(np.mean([p[1] for p in mouse_history]))
                pyautogui.moveTo(avg_x, avg_y)

            # è¨ˆç®—æ‹‡æŒ‡èˆ‡é£ŸæŒ‡çš„è·é›¢ï¼ˆåˆ¤æ–·æ˜¯å¦è§¸ç¢°ï¼‰
            dx = index_tip.x - thumb_tip.x
            dy = index_tip.y - thumb_tip.y
            dist = math.sqrt(dx * dx + dy * dy)

            # å¦‚æœè·é›¢å¾ˆè¿‘ï¼Œä¸¦ä¸”è¶…éå†·å»æ™‚é–“ï¼Œå°±è§¸ç™¼æ»‘é¼ é»æ“Š
            if dist < 0.03 and (time.time() - last_click_time) > click_cooldown:
                pyautogui.click()
                print("ğŸ–±ï¸ Clicked!")
                last_click_time = time.time()

            # å¦‚æœåµæ¸¬åˆ°æ¡æ‹³ï¼Œå°±é€€å‡ºç¨‹å¼
            if is_fist(hand_landmarks.landmark):
                print("ğŸ‘Š åµæ¸¬åˆ°æ¡æ‹³ï¼Œé€€å‡ºç¨‹å¼ï¼")
                cap.release()
                cv2.destroyAllWindows()
                hands.close()
                exit()

            # ç•«å‡ºæ‰‹éƒ¨éª¨æ¶èˆ‡é€£ç·š
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # é¡¯ç¤ºç•«é¢
    cv2.imshow("Hand Tracking", frame)

    # æŒ‰ä¸‹ ESC æˆ–é»è¦–çª—å³ä¸Šè§’é—œé–‰éƒ½èƒ½é€€å‡º
    if cv2.waitKey(1) & 0xFF == 27 or cv2.getWindowProperty("Hand Tracking", cv2.WND_PROP_VISIBLE) < 1:
        break

# è³‡æºé‡‹æ”¾
cap.release()
cv2.destroyAllWindows()
hands.close()
