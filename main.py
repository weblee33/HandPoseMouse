# ------------------ å¥—ä»¶è¼‰å…¥ ------------------
import cv2
import mediapipe as mp
import pyautogui
import time
import numpy as np
import math

# ------------------ å¯èª¿åƒæ•¸ ------------------
EMA_ALPHA           = 0.4   # æŒ‡æ•¸ç§»å‹•å¹³å‡ä¿‚æ•¸
CLICK_THRESHOLD     = 0.05  # é»æ“Šåˆ¤æ–·è·é›¢ (æ‹‡æŒ‡-é£ŸæŒ‡)
CLICK_COOLDOWN      = 0.5   # é»æ“Šå†·å»ç§’æ•¸
FIST_DIST_THRESHOLD = 0.08  # æ‹³é ­åˆ¤æ–·è·é›¢
FIST_FRAMES         = 7     # é€£çºŒå¹€æ•¸æ‰è¦–ç‚ºæ¡æ‹³
TARGET_FPS          = 30    # FPS ä¸Šé™
CAM_W, CAM_H        = 480, 270

# ------------------------------------------------
pyautogui.FAILSAFE = False
screen_w, screen_h = pyautogui.size()

# -------- MediaPipe Hands åˆå§‹åŒ– (è¼•é‡æ¨¡å‹) -------
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1,
                       min_detection_confidence=0.7,
                       model_complexity=0)

# ---------- ç‹€æ…‹è®Šæ•¸ ----------
mouse_pos_ema  = None        # EMA å¹³æ»‘æ¸¸æ¨™
last_click_time = time.time() - CLICK_COOLDOWN
prev_dist       = 1.0        # å‰ä¸€å¹€æ‹‡æŒ‡-é£ŸæŒ‡è·é›¢
fist_streak     = 0          # é€£çºŒæ¡æ‹³å¹€è¨ˆæ•¸

# ------------ æ”å½±æ©Ÿ ------------
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH,  CAM_W)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_H)
prev_time = time.time()

# ----------- å‡½å¼ï¼šåˆ¤æ–·æ¡æ‹³ -----------
def is_fist(landmarks):
    finger_tips = [8, 12, 16, 20]
    finger_pips = [6, 10, 14, 18]
    curled = sum(landmarks[tip].y > landmarks[pip].y + 0.02
                 for tip, pip in zip(finger_tips, finger_pips))
    dist = math.hypot(landmarks[8].x - landmarks[4].x,
                      landmarks[8].y - landmarks[4].y)
    return dist < FIST_DIST_THRESHOLD and curled >= 3

# ------------------ ä¸»è¿´åœˆ ------------------
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        continue

    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)

    if results.multi_hand_landmarks:
        lm = results.multi_hand_landmarks[0]

        # ----------- å–é—œéµ Landmark -----------
        thumb_tip  = lm.landmark[4]   # æ‹‡æŒ‡å°–
        index_tip  = lm.landmark[8]   # é£ŸæŒ‡å°–
        index_dip  = lm.landmark[7]   # é£ŸæŒ‡ DIPï¼ˆè¼ƒç©©å®šï¼‰

        # ----------- æ¸¸æ¨™ç§»å‹• (å¸¸æ…‹ï¼šindex_dip) ----------
        target_x = int(index_dip.x * screen_w)
        target_y = int(index_dip.y * screen_h)

        if mouse_pos_ema is None:
            mouse_pos_ema = np.array([target_x, target_y], float)
        mouse_pos_ema = (1-EMA_ALPHA)*mouse_pos_ema + EMA_ALPHA*np.array([target_x, target_y])
        pyautogui.moveTo(int(mouse_pos_ema[0]), int(mouse_pos_ema[1]))

        # ----------- æ‹‡æŒ‡-é£ŸæŒ‡è·é›¢ -----------
        dist = math.hypot(index_tip.x - thumb_tip.x,
                          index_tip.y - thumb_tip.y)

        # é‚Šç·£è§¸ç™¼é»æ“Šï¼šä¸Šä¸€å¹€è·é›¢>é–€æª»ï¼Œæœ¬å¹€<=é–€æª»
        if prev_dist > CLICK_THRESHOLD and dist <= CLICK_THRESHOLD and \
           (time.time() - last_click_time) > CLICK_COOLDOWN:

            # ä»¥ã€Œæ‹‡æŒ‡-é£ŸæŒ‡ä¸­å¿ƒé»ã€ç•¶ä½œçœŸå¯¦é»æ“Šåº§æ¨™
            center_x = int(((index_tip.x + thumb_tip.x) / 2) * screen_w)
            center_y = int(((index_tip.y + thumb_tip.y) / 2) * screen_h)
            # pyautogui.moveTo(center_x, center_y)  # æ’ä½æ¸¸æ¨™ä¸åç§»
            pyautogui.click()
            print("ğŸ–±ï¸ Clicked!")
            last_click_time = time.time()

        prev_dist = dist  # æ›´æ–°å‰ä¸€å¹€è·é›¢

        # ----------- æ¡æ‹³åˆ¤å®š -----------
        if is_fist(lm.landmark):
            fist_streak += 1
            if fist_streak >= FIST_FRAMES:
                print("ğŸ‘Š åµæ¸¬åˆ°æ¡æ‹³ï¼Œé€€å‡ºç¨‹å¼ï¼")
                break
        else:
            fist_streak = 0

    # ---------------- ç•«é¢é¡¯ç¤º ----------------
    cv2.imshow("Hand Tracking", frame)

    # é›¢é–‹æ¢ä»¶
    if cv2.waitKey(1) & 0xFF == 27 or \
       cv2.getWindowProperty("Hand Tracking", cv2.WND_PROP_VISIBLE) < 1:
        break

    # FPS æ§åˆ¶
    elapsed = time.time() - prev_time
    time.sleep(max(0, (1 / TARGET_FPS) - elapsed))
    prev_time = time.time()

# -------- è³‡æºé‡‹æ”¾ --------
cap.release()
cv2.destroyAllWindows()
hands.close()
